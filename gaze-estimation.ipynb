{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaze Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import pickle\n",
    "\n",
    "#Basic\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "#Aiding conversions from string to list\n",
    "import ast\n",
    "\n",
    "#Randomize\n",
    "import random\n",
    "\n",
    "#Labelling classifiers\n",
    "import time\n",
    "\n",
    "#Support Vector Classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from joblib import dump, load\n",
    "#from sklearn import svm, grid_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Recording a video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just record it. Falar de algumas precauções e cuidades. IDK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Converting the video in measurable data / Data treatment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Importing the text file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do so, we created [datasetGenerating.py](https://github.com/antonioramiro/gaze-estimation/blob/master/datasetGenerating.py) which converts a video into an array of (~) 47 elements. yada yada yada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``demo da datasetGenerating`` .gif e o comando q se usa "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, to cluster every vector generated, each in an individual .txt file, we used [txtJoiner](https://github.com/antonioramiro/gaze-estimation/blob/master/txtJoiner.py), which outputs the following file yada yada. When said file is imported, the lines are read as strings, therefore it needs to be converted to a list of lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#opening the file\n",
    "with open('dataset_2020-03-24.txt') as file:\n",
    "    txt_file = [line.strip() for line in file]\n",
    "\n",
    "dataset = []\n",
    "#converting a list of strings to a list of lists\n",
    "counter = 0\n",
    "total_lines = len(txt_file)\n",
    "while counter != total_lines:\n",
    "    individual_line = ast.literal_eval(txt_file[counter])\n",
    "    dataset += [individual_line]\n",
    "    counter+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 Understanding the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "meter aqui imagem do boneco, com a legenda adequada ao nosso vetor. como por aquilo bonito? fica melhor explicado por escrito do que tudo discriminado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``[x_nose, y_nose, x_right ear, y_right ear, x_left ear, y_left ear, x_right eye, y_right eye, x_left eye, y_left eye, x_right hand, y_right hand, x_left hand, y_left hand, ... contextual information - 32 positions ..., quadrant]``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Increasing sample size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inverter horizontalmente as cenas + termos o dobro dos dados. nota: a geradora do dataset cospe a resolução das imagens na sua penúltima linha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initially, the dataset is composed by 11 elements.\n"
     ]
    }
   ],
   "source": [
    "print('Initially, the dataset is composed by ' + str(len(dataset)) + ' elements.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resolution = (640,352) \n",
    "flipped_dataset = []\n",
    "\n",
    "# Calculate the simetric quadrant, where the input is an int and the output is a list of 1 element.\n",
    "# Given the numeration of quadrants (stated in 2.1.1), a simple addition/subtraction of 3 or 5 will yield\n",
    "# the simetric quadrant\n",
    "\n",
    "def flipped_quadrant(quadrant):\n",
    "    if quadrant in [1,3,9,11]:\n",
    "        flipped_quadrant = quadrant + 3 \n",
    "    elif quadrant in [4,6,12,14]:\n",
    "        flipped_quadrant = quadrant - 3 \n",
    "    elif quadrant in [0,2,8,10]:\n",
    "        flipped_quadrant = quadrant + 5\n",
    "    elif quadrant in [5,7,13,15]:\n",
    "        flipped_quadrant = quadrant - 5  \n",
    "    return [flipped_quadrant]\n",
    "    \n",
    "\n",
    "for element in dataset:\n",
    "    flipped_element = []\n",
    "    for i in range(len(element) - 33):\n",
    "        \n",
    "        # Every even index (up to the 14th: indexes that correspond to coordinates of poseKeypoints) contains \n",
    "        # an X coordinate, from which can be obtained the simetric coordinate (by subtracting to the width\n",
    "        # the original X), note that Y is irrelevant to horizontal simetry.\n",
    "        \n",
    "        if i%2 == 0 and element[i] != -1: #x\n",
    "            flipped_element += [resolution[0] - element[i]]\n",
    "                                            \n",
    "        else: #y or x == -1\n",
    "            flipped_element += [element[i]]       \n",
    "        \n",
    "    flipped_dataset += [flipped_element + element[14:-1] + flipped_quadrant(element[-1])]\n",
    "\n",
    "dataset += flipped_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now, it has 22 elements.\n"
     ]
    }
   ],
   "source": [
    "print('Now, it has ' + str(len(dataset)) + ' elements.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Leveling the data - corrigir numeracao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll try to minimize the dataset bias by selecting the quadrant with the least amount of samples and a percentage in which the rest of the samples may differ. This way, we'll delete the excess samples from the other quadrants.  Due to XXXX, some quadrants tend to be more prevalent. So in order not to confuse :p the SVM, the values should be more homogenized  Falar um pouco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly lets visualise the distributtion of data with the following function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np; np.random.seed(0)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import random\n",
    "%matplotlib inline\n",
    "\n",
    "def heatmap (dataset):\n",
    "    #in the quadrant_count list, each number corresponds to the number of samples where the object is in that\n",
    "    #quadrant so quadrant_count[0] is the number of samples in the 0 quadrant\n",
    "    quadrant_count=[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "    for i in range(len(dataset)):\n",
    "        quad=dataset[i][-1]\n",
    "        quadrant_count[quad]=quadrant_count[quad]+1\n",
    "    data=[[quadrant_count[0],quadrant_count[1],quadrant_count[4],quadrant_count[5]],\\\n",
    "           [quadrant_count[2],quadrant_count[3],quadrant_count[6],quadrant_count[7]],\\\n",
    "           [quadrant_count[8],quadrant_count[9],quadrant_count[12],quadrant_count[13]],\\\n",
    "           [quadrant_count[10],quadrant_count[11],quadrant_count[14],quadrant_count[15]]]\n",
    "    sns.heatmap(data, annot=True, fmt=\"d\",linewidths=0.5,yticklabels=False,xticklabels=False,cbar=False)\n",
    "    return quadrant_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prior to leveling, we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 2, 1, 3, 1, 1, 1, 1, 1, 5, 1, 1, 1, 1, 1, 2]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAADnCAYAAAC9roUQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBUgkugCJRBcg0f8BTFA2SQKqXLoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15f24461908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset=[[1,1,0],[2,2,0],[1,2,1],[1,2,1],[0,0,2],[1,3,3],[3,2,3],[1,2,3],[1,5,4],[5,5,5],[1,2,6],[1,2,7],[6,2,8],[1,3,9],[2,3,9],[3,3,9],[4,3,9],[5,3,9],[3,0,10],[1,3,11],[1,2,12],[3,3,13],[4,4,14],[5,3,15],[2,3,15]]\n",
    "heatmap(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we shall define the levelling function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def levelling (dataset,percent):\n",
    "    #percent indicates de percentage of samples we'll allow of difference \n",
    "    #between the smallest samples and all the rest\n",
    "    quadrant_count=heatmap(dataset)\n",
    "    a=quadrant_count[0]\n",
    "    #we'll use the following cycle to find out what is the smallest number of samples we have in one quadrant\n",
    "    #(doesn't matter which quadrant that is)\n",
    "    for i in quadrant_count:\n",
    "        if i<a:\n",
    "            a=i\n",
    "    max=(percent+1)*a\n",
    "    excess=[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "    for i in range(len(quadrant_count)):\n",
    "        if quadrant_count[i]>max:\n",
    "            excess[i]=quadrant_count[i]-max\n",
    "        else:\n",
    "            excess[i]=0\n",
    "    while sum(excess)!=0:\n",
    "        sample=random.randint(0,len(dataset))-1\n",
    "        quad=dataset[sample][-1]\n",
    "        if excess[quad]!=0:\n",
    "            dataset=dataset[:sample]+dataset[sample+1:]\n",
    "            excess[quad]=excess[quad]-1\n",
    "    heatmap(dataset)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And apply it to our data, seeing a more homogeneyus ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 0],\n",
       " [2, 2, 0],\n",
       " [1, 2, 1],\n",
       " [1, 2, 1],\n",
       " [0, 0, 2],\n",
       " [3, 2, 3],\n",
       " [1, 2, 3],\n",
       " [1, 5, 4],\n",
       " [5, 5, 5],\n",
       " [1, 2, 6],\n",
       " [1, 2, 7],\n",
       " [6, 2, 8],\n",
       " [1, 3, 9],\n",
       " [2, 3, 9],\n",
       " [3, 0, 10],\n",
       " [1, 3, 11],\n",
       " [1, 2, 12],\n",
       " [3, 3, 13],\n",
       " [4, 4, 14],\n",
       " [5, 3, 15],\n",
       " [2, 3, 15]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAADnCAYAAAC9roUQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAACNpJREFUeJzt3V9oXvUZwPEn5k2sKVvDljE0k43cyi4czorVQYorDiel\nW2tXcCbpHCmzqRq8aKL2QjpFbwbe2A2ZpUOEDcWWCWNMvLETduNdLnqRuxexfTtr1pr65oR3F/65\nS4Pt8Tk9p5/PXXIaeHj4vd+enBZOX6/XCwByXFf1AADXEtEFSCS6AIlEFyCR6AIkaq1z3X9tAPjq\n+ta6sF50Y6WzWO4o16iBkbGIsM+yDIyMRWtwtOoxGqPotu2zJEW3fcnrHi8AJBJdgESiC5BIdAES\niS5AItEFSCS6AIlEFyCR6AIkEl2ARKILkEh0ARKJLkAi0QVIJLoAiUQXIJHoAiQSXYBEoguQSHQB\nEokuQCLRBUhU6+iuFEXMPftiTMzMx57pJ+Kd996veqTassuvx+TE7uicXqh6jEZoyi5bVQ9wJd56\n+2QMb9oUz80fiHNL52PX1EyMv/5K1WPVkl2W78TxY7F1fEsUxWrVo9Rek3ZZ6zvdbXdvjv1TD3z5\ndX+r1n+HVMouy7ewcCq275iseoxGaNIuax3doaENsXHohrjwyXLMHno+ZvZNVT1Sbdll+Q7OHY7l\n5YtVj9EITdplraMbEfHBmbOx99Gn4v5774n7xu+sepxas0v4+tX6d8jOR0sxPft0PDn7SGy+9Zaq\nx6k1u4QctY7uy6++EUtLS3Hk6Gtx5Ohn33vphUOx4frBSueqI7uEHH29Xu9S13srncWsWRptYGQs\nIiLssxwDI2PRGhyteozGKLpt+yxJ0W1HRPStdb32z3QB6kR0ARKJLkAi0QVIJLoAiUQXIJHoAiQS\nXYBEoguQSHQBEokuQCLRBUgkugCJRBcgkegCJBJdgESiC5BIdAESiS5AItEFSCS6AIlEFyDRuq9g\nzxoEoEHWfAV7a72fbA2OljvKNarotiMiYqWzWPEkzTAwMuZslqjotu2zJF981tfi8QJAItEFSCS6\nAIlEFyCR6AIkEl2ARKILkEh0ARKJLkAi0QVIJLoAiUQXIJHoAiQSXYBEoguQSHQBEokuQCLRBUgk\nugCJRBcgkegCJBJdgES1j+7kxO7onF6oeozaWymKmHv2xZiYmY8900/EOyf/U/VIjeB8lqcpu2xV\nPcCVOHH8WGwd3xJFsVr1KLX31r/ejeHh4Xhu/kB8fOHT2PnQvhjfcnvVY9Wa81meJu2y1ne6Cwun\nYvuOyarHaIRtP9kc+yd2fvbFda3o76/10bgqOJ/ladIua/3JOjh3OJaXL1Y9RiMMDd0QGzcOxcW+\noXh8/pmYmd5b9Ui153yWp0m7rHV0KdcHH56Jh6Yejp/fc1ds3/mriOireiRonFo/06U8Z893Y3r2\n6Zh/fDru+PGPqh4HGsudLhER8aeX/xxL/zsff/zL6zF14Kn49YMPxsVPm/HrHFxN+nq93qWu91qD\no1mzNFrRbUdExEpnseJJmmFgZCyczfIU3bZ9luTzz/qaz+bc6QIkEl2ARKILkEh0ARKJLkAi0QVI\nJLoAiUQXIJHoAiQSXYBEoguQSHQBEokuQCLRBUgkugCJRBcgkegCJBJdgESiC5BIdAESiS5AItEF\nSLTuK9izBgFoEK9gB7gatNb9A4OjGXM0XtFtR0TESmex4kmaYWBkzNksUdFt22dJvvisr8WdLkAi\n0QVIJLoAiUQXIJHoAiQSXYBEoguQSHQBEokuQCLRBUgkugCJRBcgkegCJBJdgESiC5BIdAESiS5A\nItEFSCS6AIlEFyCR6AIkEl2ARLWP7uTE7uicXqh6jNpbKYq4895dcce2X8btP/1F/ObAwapHagTn\nszxN2WWr6gGuxInjx2Lr+JYoitWqR6m9N//+z+jvvy7+/Y+/xbmPl2Ln1P6qR6o957M8Tdplre90\nFxZOxfYdk1WP0Qjfv3k0vrFxY/z2sfmYOfhMrK7W/3BXzfksT5N2WevoHpw7HMvLF6seoxGGh78Z\nex/cFX/4/ZNRFEWsFquNuKuokvNZnibtstbRpTw/uHk0brv1h7F3Zi52bf9Z3HTjd+PM2f9WPRY0\njugSERHH/vpm7Hn4sZj93VTctfm2uHDhk/jOt79V9VjQOLX+hzTK8+HpTnza7cZj84cjIuJ7N90Y\nxWoRrVZ/xZNBs/T1er1LXe+1BkezZmm0otuOiIiVzmLFkzTDwMhYOJvlKbpt+yzJ55/1vrWue7wA\nkEh0ARKJLkAi0QVIJLoAiUQXIJHoAiQSXYBEoguQSHQBEokuQCLRBUgkugCJRBcgkegCJBJdgESi\nC5BIdAESiS5AItEFSCS6AIlEFyDRuq9gzxoEoEHWfAV7a72fbA2OljvKNarotiPCPstSdNt2WaKi\n246VzmLVYzTCwMjYJa97vACQSHQBEokuQCLRBUgkugCJRBcgkegCJBJdgESiC5BIdAESiS5AItEF\nSCS6AIlEFyCR6AIkEl2ARKILkEh0ARKJLkAi0QVIJLoAiUQXIFHtozs5sTs6pxeqHqMx7LNc9lmO\nlaKIuWdfjImZ+dgz/US88977VY902VpVD3AlThw/FlvHt0RRrFY9SiPYZ7nsszxvvX0yhjdtiufm\nD8S5pfOxa2omxl9/peqxLkut73QXFk7F9h2TVY/RGPZZLvssz7a7N8f+qQe+/Lq/Vd/7xVpH9+Dc\n4Vhevlj1GI1hn+Wyz/IMDW2IjUM3xIVPlmP20PMxs2+q6pEuW62jC1w7PjhzNvY++lTcf+89cd/4\nnVWPc9nqe48OXDM6Hy3F9OzT8eTsI7H51luqHueKiC5w1Xv51TdiaWkpjhx9LY4c/ex7L71wKDZc\nP1jpXJejr9frXep6rzU4mjVLoxXddkRE2Gc5im7bLktUdNux0lmseoxGGBgZi4joW+u6Z7oAiUQX\nIJHoAiQSXYBEoguQSHQBEokuQCLRBUgkugCJRBcgkegCJBJdgESiC5BIdAESiS5AItEFSCS6AIlE\nFyCR6AIkEl2ARKILkEh0ARKt+wr2rEEAGmTNV7C3LvcHAfjqPF4ASCS6AIlEFyCR6AIkEl2ARKIL\nkOj/Yak8lDOhuQMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15f24472400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "levelling(dataset,1)\n",
    "\n",
    "#guardar o novo dataset em dataset, var global"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Separating data for testing and for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's get the party going. Separate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "size = len(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_frames = len(dataset)\n",
    "testing_data = []\n",
    "training_data = []\n",
    "\n",
    "for i in range(int(0.2*total_frames)):\n",
    "    element_to_transfer = random.choice(dataset)\n",
    "    testing_data += [element_to_transfer]\n",
    "    dataset.remove(element_to_transfer)\n",
    "\n",
    "training_data = dataset\n",
    "dataset = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4, 0.18181818181818182), (18, 0.8181818181818182))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(testing_data),len(testing_data)/size),(len(training_data),len(training_data)/size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training the models & Classifying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Creating a proper list of vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este step is only done here in order to reduce the probability of messing up and disconecting each X vector from the correspondant Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eXifY(data):\n",
    "    X, Y = [element[0:-1] for element in data], [element[-1] for element in data]\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(eXifY(training_data)[0]) == len(eXifY(training_data)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Training & Classifying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como o obj. é comparar a qualidade das classificações consoante o tipo de contxt dado, vamos treinar 4 modelos e testá-los e ver as diferenças, assim ta pa treinar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-19-ad63199ebc2b>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-19-ad63199ebc2b>\"\u001b[1;36m, line \u001b[1;32m7\u001b[0m\n\u001b[1;33m    def coordsandquadrvectors(linestxt)\u001b[0m\n\u001b[1;37m                                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def trainning(X,y):\n",
    "    \n",
    "    #tudo o que está ali abaixo, depois entrava aqui\n",
    "    \n",
    "    tipo = (exemplo) # exemplo mal feito para depois identificares no nome qual o tipo de dados\n",
    "        if len(X) = 46 (tudo) #nao vi bem os nrs\n",
    "        if len(X) = 10 (cabeca)\n",
    "        if len(X) = 14 (cabeca e maos)\n",
    "        if len(X) = 43 (cabeca e contexto)\n",
    "    return 'classificador com data e tipo^ de dados no nome.joblib','info do classif,+ +tipo + n da amostra.txt' \n",
    "\n",
    "\n",
    "#Opening the traindata file with all the coordinates of the important points.\n",
    "#The last number of each line is the number of the quadrant \n",
    "with open(\"traindata.txt\") as file: #ATTENTION: this filename comes from elsewhere, change if needed\n",
    "    linestrain = [line.strip() for line in file] #erases the empty spaces in each line from the txt file\n",
    "\n",
    "    \n",
    "def coordsandquadrvectors(linestxt)\n",
    "\n",
    "#Initialization  \n",
    "numberquad = [] \n",
    "Allthecoords = [] \n",
    "counter = 0\n",
    "\n",
    "length = len(linestxt)\n",
    "\n",
    "#This cicle separates, in each line corresponding to one image\n",
    "#the coordinates to the Allthecoords vector and the quadrant number to the numberquad vector\n",
    "while counter != length:\n",
    "    omega = ast.literal_eval(linestxt[counter]) # ast.literal_eval raises an exception if the input isn't a valid Python datatype, so the code won't be executed if it's not\n",
    "    Allthecoords += [omega[:10]]\n",
    "    if omega[-1] == -1: #if the quadrant number is -1 (mistakenly) it is replaced by the quadrant 0\n",
    "        numberquad +=[0]\n",
    "    else:\n",
    "        numberquad +=[omega[-1]]\n",
    "    counter+=1\n",
    "\n",
    "return Allthecoords, numberquad, length\n",
    "\n",
    "CoordsTrain, quadTrain = coordsandquadrvectors(linestrain)\n",
    "    \n",
    "#This function below selects the best parameters that will there be used with the SVC\n",
    "def svc_param_selection(X, y, nfolds):\n",
    "    Cs = [1000,100] #parameter 1\n",
    "    gammas = [1e-06] #parameter 2  \n",
    "    param_grid = {'C': Cs, 'gamma' : gammas} #all in one grid\n",
    "    grid_search2 = grid_search.GridSearchCV(svm.SVC(kernel='rbf'), param_grid, cv=nfolds)\n",
    "    grid_search2.fit(X, y)\n",
    "    grid_search2.best_params_\n",
    "    return grid_search2.best_params_\n",
    "    \n",
    "best = svc_param_selection(CoordsTrain, quadTrain, 3) #3 means a 3-fold cross-validation\n",
    "\n",
    "clf = SVC(C= best['C'],gamma=best['gamma']) #creating the model with the best parameters\n",
    "clf.fit(CoordsTrain, quadTrain) #fitting the model to the data\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "timestamp = str(now.strftime(\"%Y%m%d_%H-%M-%S\")) #the current day and time to have to the classifier name \n",
    "\n",
    "classif_name = \"classifier_\"+timestamp+\".joblib\" \n",
    "\n",
    "dump(clf,classif_name, protocol=2) #creating the classifier file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "assim ta pa testar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def testing(X,y,classif)\n",
    "\n",
    "    meter considerações osbre a eficácia deste classificador no .txt criado anteriormente\n",
    "    return conf matrixes e printar considerações\n",
    "    mete o classif em variavel global, para depois o poder puxar sem ter de dizer o nome do ficheiro\n",
    "\n",
    "\n",
    "\n",
    "#ATTENTION: the covariance matrices comments are TEMPORARY since we don't know if it's necessary (one method is implemented but not sure if it's the right one)\n",
    "\n",
    "#Opening the testdata file with all the coordinates of the important points.\n",
    "#The last number of each line is the number of the quadrant \n",
    "with open(\"testdata.txt\") as file: #ATTENTION: this filename comes from elsewhere, change if needed\n",
    "    linestest = [line.strip() for line in file]\n",
    "\n",
    "coordsTest,quadTest, lengthtest = coordsandquadrvectors(linestest)  \n",
    "\n",
    "#Predicting part: using the classifier to predict \n",
    "#(NOT USING THE FILE SAVED, IT ONLY RUNS IF THE CLASSIFIER WAS BUILT IN THE SAME SESSION)\n",
    "\n",
    "#Extra Initialization \n",
    "Qpredicted= []\n",
    "nmatching = 0 #number of right predictions\n",
    "confMatrix = np.zeros((16,16))\n",
    "i=0\n",
    "\n",
    "while i != lengthtest:\n",
    "Qpredicted+= [str(clf2.predict(np.array([coordsTest[i]]))).strip('['+']')] #predict\n",
    "quadTest[i]= str(quadTest[i]) #converting to a string\n",
    "    \n",
    "confMatrix[int(Qpredicted[i])][int(quadTest[i])] += 1 \n",
    "    \n",
    "if Qpredicted[i] == quadTest[i]:\n",
    "    nmatching+=1\n",
    "    \n",
    "i+=1\n",
    "\n",
    "persucess = (float(nmatching)/float(lengthtest)) * 100  \n",
    "\n",
    "\n",
    "print('The percentage of success was: ' + str(persucess)+ ' %')\n",
    "\n",
    "#print(str(confMatrix))\n",
    "\n",
    "#def sum1(input):\n",
    " #   sum = 0\n",
    "  #  for row in range (len(input)):\n",
    "   #     for col in range(len(input[0])):\n",
    "    #        sum = sum + input[row][col]\n",
    "\n",
    "#    return sum\n",
    "#print(sum1(confMatrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 Using only the face keypoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're using only the keypoints of the face, we'll delete context info (short/long) and hands coordinates. As coords da cara são os 10 primeiros items 5*2 (x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = eXifY(training_data)\n",
    "X = [i[:10] for i in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 6, 13, 13, 6, 6, 6, 12, 6, 3, 2, 3, 3, 3, 3, 8, 9, 3]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dizer coisas aqui sobre o que se vai passar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainning(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now ... Dizer coisas aqui sobre o que se vai passar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = eXifY(testing_data)\n",
    "X = [i[:10] for i in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testing(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 Using only keypoints (face + hands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're using only the keypoints, we'll delete context info (short/long). os 14 primeiros items 5*2 (x,y) da cara  + 2*2 (x,y) das mãos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = eXifY(training_data)\n",
    "X = [i[:12] for i in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainning(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = eXifY(testing_data)\n",
    "X = [i[:12] for i in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testing(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 Using only the keypoints of the face and context data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're using only the keypoints, we'll delete hands coordinates. #primeiros 10 + do 15 até ao 46"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = eXifY(training_data)\n",
    "X = [i[:10] + i[14:] for i in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainning(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = eXifY(testing_data)\n",
    "X = [i[:10] + i[14:] for i in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testing(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 Using they keypoints of the face, hands and context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're using only the keypoints, we'll delete context info (short/long) and hands coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = eXifY(training_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = eXifY(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testing(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Comparing classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fazer conf. matrix bonita https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
