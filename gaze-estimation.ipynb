{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaze Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import math\n",
    "\n",
    "#Aiding conversions from string to list\n",
    "import ast\n",
    "\n",
    "#Randomize\n",
    "import random\n",
    "\n",
    "#Labelling classifiers\n",
    "import datetime\n",
    "import joblib\n",
    "\n",
    "#Support Vector Classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from joblib import dump, load\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm\n",
    "#Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from pandas import DataFrame\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Recording a video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just record it. Falar de algumas precauções e cuidades. IDK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Converting the video in measurable data / Data treatment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Importing the text file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do so, we created [datasetGenerating.py](https://github.com/antonioramiro/gaze-estimation/blob/master/datasetGenerating.py) which converts a video into an array of (~) 47 elements. yada yada yada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``demo da datasetGenerating`` .gif e o comando q se usa "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, to cluster every vector generated, each in an individual .txt file, we used [txtJoiner](https://github.com/antonioramiro/gaze-estimation/blob/master/txtJoiner.py), which outputs the following file yada yada. When said file is imported, the lines are read as strings, therefore it needs to be converted to a list of lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the file\n",
    "with open('dataset_2020-05-12.txt') as file:\n",
    "    txt_file = [line.strip() for line in file]\n",
    "\n",
    "dataset = []\n",
    "#converting a list of strings to a list of lists\n",
    "counter = 0\n",
    "total_lines = len(txt_file)\n",
    "while counter != total_lines:\n",
    "    individual_line = ast.literal_eval(txt_file[counter])\n",
    "    dataset += [individual_line]\n",
    "    counter+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 Understanding the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "meter aqui imagem do boneco, com a legenda adequada ao nosso vetor. como por aquilo bonito? fica melhor explicado por escrito do que tudo discriminado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``[x_nose, y_nose, x_neck, y_neck, x_right ear, y_right ear, x_left ear, y_left ear, x_right eye, y_right eye, x_left eye, y_left eye, x_right hand, y_right hand, x_left hand, y_left hand, ... contextual information - 32 positions ..., quadrant]``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Separating data for testing and for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's get the party going. Separate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data = dataset[int(len(dataset)*0.8):]\n",
    "training_data = dataset[:int(len(dataset)*0.8)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "old way\n",
    "size = \n",
    "\n",
    "total_frames = \n",
    "\n",
    "\n",
    "for i in range(int(0.2*total_frames)):\n",
    "    element_to_transfer = random.choice(dataset)\n",
    "    testing_data += [element_to_transfer]\n",
    "    dataset.remove(element_to_transfer)\n",
    "\n",
    "training_data = dataset\n",
    "dataset = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "(len(testing_data),len(testing_data)/size),(len(training_data),len(training_data)/size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Increasing sample size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inverter horizontalmente as cenas + termos o dobro dos dados. nota: a geradora do dataset cospe a resolução das imagens na sua penúltima linha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initially, the training dataset is composed by 8209 elements.\n"
     ]
    }
   ],
   "source": [
    "print('Initially, the training dataset is composed by ' + str(len(training_data)) + ' elements.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataDoubler(dataset):\n",
    "    resolution = (640,352) \n",
    "    flipped_dataset = []\n",
    "\n",
    "# Calculate the simetric quadrant, where the input is an int and the output is a list of 1 element.\n",
    "# Given the numeration of quadrants (stated in 2.1.1), a simple addition/subtraction of 3 or 5 will yield\n",
    "# the simetric quadrant\n",
    "\n",
    "    def flipped_quadrant(quadrant):\n",
    "        if quadrant in [1,3,9,11]:\n",
    "            flipped_quadrant = quadrant + 3 \n",
    "        elif quadrant in [4,6,12,14]:\n",
    "            flipped_quadrant = quadrant - 3 \n",
    "        elif quadrant in [0,2,8,10]:\n",
    "            flipped_quadrant = quadrant + 5\n",
    "        elif quadrant in [5,7,13,15]:\n",
    "            flipped_quadrant = quadrant - 5  \n",
    "        return [flipped_quadrant]\n",
    "\n",
    "\n",
    "    for element in dataset:\n",
    "        flipped_element = []\n",
    "        for i in range(len(element) - 33):\n",
    "\n",
    "            # Every even index (up to the 14th: indexes that correspond to coordinates of poseKeypoints) contains \n",
    "            # an X coordinate, from which can be obtained the simetric coordinate (by subtracting to the width\n",
    "            # the original X), note that Y is irrelevant to horizontal simetry.\n",
    "\n",
    "            if i%2 == 0 and element[i] != -1: #x\n",
    "                flipped_element += [resolution[0] - element[i]]\n",
    "\n",
    "            else: #y or x == -1\n",
    "                flipped_element += [element[i]]       \n",
    "\n",
    "        flipped_dataset += [flipped_element + element[14:-1] + flipped_quadrant(element[-1])]\n",
    "\n",
    "    dataset += flipped_dataset\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = dataDoubler(training_data)\n",
    "testing_data = dataDoubler(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now, it has 16418 elements.\n"
     ]
    }
   ],
   "source": [
    "print('Now, it has ' + str(len(training_data)) + ' elements.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[229.07858, 94.234505, 195.64702, 120.07037, 209.91275, 96.15271, -1, -1, 224.29808, 88.51399, 226.23778, 88.47061, 195.58241, 179.3321, 196.58733, 165.00067, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1]\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0])\n",
    "print(len(dataset[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def head_angle(x_nose,y_nose,x_neck,y_neck):\n",
    "    #angle() calculates the angle at which the head is tilted using the coordinates of the nose and neck\n",
    "    if x_nose>=0 and x_neck>=0:\n",
    "        x=abs(x_nose-x_neck)\n",
    "        y=abs(y_nose-y_neck)\n",
    "        angle=math.atan(y/x)\n",
    "        if x_nose-x_neck<0:\n",
    "            angle+=math.pi/2\n",
    "        return [angle]\n",
    "    else:\n",
    "        return [-1]\n",
    "\n",
    "    \n",
    "def hand_distance(x_rhand,y_rhand,x_lhand,y_lhand,x_nose,y_nose):\n",
    "    #hand_distance() calculates the distance between the hands and the face using the nose coordinates\n",
    "    right=-1\n",
    "    left=-1\n",
    "    if x_rhand>=0 and x_nose>=0:\n",
    "        right=math.sqrt((x_rhand-x_nose)**2+(y_rhand-y_nose)**2)\n",
    "        \n",
    "    if x_lhand>=0 and x_nose>=0:\n",
    "        left=math.sqrt((x_lhand-x_nose)**2+(y_lhand-y_nose)**2)\n",
    "    \n",
    "    distances=[right,left]\n",
    "    return distances\n",
    "\n",
    "\n",
    "def hand_angles(x_rhand,y_rhand,x_lhand,y_lhand,x_neck,y_neck):\n",
    "    #hand_angles() calculates the angle between each arm and the horizontal axis\n",
    "    r_angle=-1\n",
    "    l_angle=-1\n",
    "    if x_rhand>=0 and x_neck>=0:\n",
    "        x=abs(x_rhand-x_neck)\n",
    "        y=abs(y_rhand-y_neck)\n",
    "        r_angle=math.atan(y/x)\n",
    "    if x_lhand>=0 and x_neck>=0:\n",
    "        x=abs(x_lhand-x_neck)\n",
    "        y=abs(y_lhand-y_neck)\n",
    "        l_angle=math.atan(y/x)\n",
    "        \n",
    "    angles=[r_angle,l_angle]\n",
    "    return angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dataset:\n",
    "    add=head_angle(i[0],i[1],i[2],i[3]) + hand_distance(i[12],i[13],i[14],i[15],i[0],i[1]) + hand_angles(i[12],i[13],i[14],i[15],i[2],i[3])\n",
    "dataset = [i[:-1] + add + [i[-1]] for i in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[229.07858, 94.234505, 195.64702, 120.07037, 209.91275, 96.15271, -1, -1, 224.29808, 88.51399, 226.23778, 88.47061, 195.58241, 179.3321, 196.58733, 165.00067, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1.2814020358982958, 196.50944297506547, 187.21284329327221, 1.3582749993269967, 1.0564549249678774, 1]\n",
      "54\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0])\n",
    "print(len(dataset[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Leveling the data - corrigir numeracao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em vez de leveling, outra palavra para descrever este processo de fazer os numeros mais proximos.  Due to XXXX, some quadrants tend to be more prevalent. So in order not to confuse :p the SVM, the values should be more homogenized  Falar um pouco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly lets visualise the distributtion of data with the following function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np; np.random.seed(0)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import random\n",
    "%matplotlib inline\n",
    "\n",
    "def heatmap (dataset):\n",
    "    #in the quadrant_count list, each number corresponds to the number of samples where the object is in that\n",
    "    #quadrant so quadrant_count[0] is the number of samples in the 0 quadrant\n",
    "    quadrant_count=[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "    for i in range(len(dataset)):\n",
    "        quad=dataset[i][-1]\n",
    "        quadrant_count[quad]=quadrant_count[quad]+1\n",
    "    data=[[quadrant_count[0],quadrant_count[1],quadrant_count[4],quadrant_count[5]],\\\n",
    "           [quadrant_count[2],quadrant_count[3],quadrant_count[6],quadrant_count[7]],\\\n",
    "           [quadrant_count[8],quadrant_count[9],quadrant_count[12],quadrant_count[13]],\\\n",
    "           [quadrant_count[10],quadrant_count[11],quadrant_count[14],quadrant_count[15]]]\n",
    "    sns.heatmap(data, annot=True, fmt=\"d\",linewidths=0.5,yticklabels=False,xticklabels=False,cbar=False)\n",
    "    return quadrant_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prior to leveling, we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[336,\n",
       " 218,\n",
       " 1369,\n",
       " 1312,\n",
       " 218,\n",
       " 336,\n",
       " 1312,\n",
       " 1369,\n",
       " 1160,\n",
       " 2144,\n",
       " 435,\n",
       " 1235,\n",
       " 2144,\n",
       " 1160,\n",
       " 1235,\n",
       " 435]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#dataset=[[1,1,0],[2,2,0],[1,2,1],[1,2,1],[0,0,2],[1,3,3],[3,2,3],[1,2,3],[1,5,4],[5,5,5],[1,2,6],[1,2,7],[6,2,8],[1,3,9],[2,3,9],[3,3,9],[4,3,9],[5,3,9],[3,0,10],[1,3,11],[1,2,12],[3,3,13],[4,4,14],[5,3,15],[2,3,15]]\n",
    "heatmap(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def levelling (dataset,percent):\n",
    "    #percent indicates de percentage of samples we'll allow of difference \n",
    "    #between the smallest samples and all the rest\n",
    "    quadrant_count=heatmap(dataset)\n",
    "    a=quadrant_count[0]\n",
    "    #we'll use the following cycle to find out what is the smallest number of samples we have in one quadrant\n",
    "    #(doesn't matter which quadrant that is)\n",
    "    for i in quadrant_count:\n",
    "        if i<a:\n",
    "            a=i\n",
    "    max=int((percent+1)*a)\n",
    "    excess=[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "    for i in range(len(quadrant_count)):\n",
    "        if quadrant_count[i]>max:\n",
    "            excess[i]=quadrant_count[i]-max\n",
    "        else:\n",
    "            excess[i]=0\n",
    "    \n",
    "    b=[[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]]\n",
    "    for j in dataset:\n",
    "        b[j[-1]]+=[j]\n",
    "    for k in range(len(b)):\n",
    "        for l in range(excess[k]):\n",
    "            c=random.choice(b[k])\n",
    "            b[k].remove(c)\n",
    "    dataset=[]\n",
    "    for m in b:\n",
    "        dataset+=m\n",
    "    random.shuffle(dataset)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[336,\n",
       " 218,\n",
       " 479,\n",
       " 479,\n",
       " 218,\n",
       " 336,\n",
       " 479,\n",
       " 479,\n",
       " 479,\n",
       " 479,\n",
       " 435,\n",
       " 479,\n",
       " 479,\n",
       " 479,\n",
       " 479,\n",
       " 435]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWkAAADzCAYAAABE8effAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAE5xJREFUeJzt3Hl01eWdx/HP725JbkhCVgKCaNgiKhEUUXCpFbFTnRkXCnWhiBarIwxuoKCAitEWENQCooCIpQVsLTh6rFW0FkFAMVhPq0JYAgSy76u5y2/+AFI7XY7JXPw9l/t+/Zeb+5jn+XKeN+F3z9GybVsAADO5nN4AAOCfI9IAYDAiDQAGI9IAYDAiDQAGI9IAYDAiDQAGI9IAYDAiDQAGI9IAYDAiDQAG83RyHf/DDwDoOKujCzobab3V7YedXYqv+V7ZWkmSx3eKwzs5OQTbDjPLCAq2HeauR8jxu95RPO4AAIMRaQAwGJEGAIMRaQAwGJEGAIMRaQAwGJEGAIMRaQAwGJEGAIMRaQAwGJEGAIMRaQAwGJEGAIMRaQAwGJEGAIMRaQAwGJEGAIMRaQAwGJEGAIMRaQAwGJEGAIMRaQAwWHRH2uPSxVsXauSelbq88EWlDh+ozFFDNHLPixq5Z6VGvD9P8hw9Ys4912nk3pUauffY6/g78fHx2r3rQ1VVfKHa6t169NGp7d/7ePtb+sWqRe1fb1j/kupqC1VXU6j8/OlObNdozDLCYviuR3Wk+z0wRpK0se8E7Zn7a+Utnawz50/U7ifWaWPfCXLFe9XvgbHyZXVVn3uu1YdXzNDGPhPUerhS/r7dHd69eZ595nHV1TYoPfMMnTt0lB6YOkkD+vdRyeHPdNZZue3v69XrFH3vysvUvUeeBp3zXd13zx0O7tpMzDKyYvmue5zewP9HYf5a7Z33G0lSlwE9Faxv1ubvTJWCYbn8PnmT/Wo5WK6eN1yqtvJanferB+RNT1bpa1vVvKfE4d2b5+GZP5XL9de/t23bVmZWuqbPyNe4m0e3v15RUaWmpmZlZqYrIyNNtu3Ebs3GLCMrlu96VP8mLUnhtqAu2fa0et78XR1et0kKhpVyXj+N3P2iXAk+VW3+s+K6pym+R7oKbnlKH1x4t3qMvkjplw5yeuvGKS+vVGlpubKzs7Ttwzf1wvLV2rz5I720at3fvbemtk67v9yirVve0JtvbnRgt2ZjlpEXq3c96iMtSZsuuFtbvjNN/R4cI296kup2FOrtnjer7PXtGrpmur4qrVVbdb0avzyktsp6Ne0tUebleU5v20hDhw7Wri+2aMNrv9OUKQ//w/dMnz5ZKcnJyux2pjKyBurSS4dr/Lgx3/JOzccsIy8W73pUR3rg3Nt07tqjH7S01TZKki7evEBpl5wlSQrUNcm2bZW+sU3e1CT5c7rL5fPIf3q2qrd+4di+TTVwYH+9/95v9ehjT2ni7ff90/eVlpQrEAiovr5B9fUNamltVXZ25re4U/Mxy8iK5btu2Z17CGa/1e2Hkd5Lh3nTkzT8nSflSfLLclk6sPwttRRXKnf2zbLDYYXbgtoxJl8Nnx9U7uPj1eum70qSqrd+rk9u/JnDuz/qe2VrJUke3ykO70Ta8dHvdfbZZ6ihobH9tb79L1RtbZ3efefXOnKkTOPGT5IkvbfxNxoyZJBs29aXX+7RhSOucmrbfyPYdphZRlCw7bC465Fx7K5bHV0X1ZE+GZgU6ZOBKZE+WZgS6ZNBZyMd1Y87AOBkR6QBwGBEGgAMRqQBwGBEGgAMRqQBwGBEGgAMRqQBwGBEGgAMRqQBwGBEGgAMRqQBwGBEGgAMRqQBwGBEGgAMRqQBwGBEGgAMRqQBwGBEGgAMRqQBwGBEGgAMRqQBwGCWbdudWdepRQAQ46yOLvB09icFKvd1dim+xpuRI4l5Roo3I4dZRhDzjJzjd72jeNwBAAYj0gBgMCINAAYj0gBgMCINAAYj0gBgMCINAAYj0gBgMCINAAYj0gBgMCINAAYj0gBgMCINAAYj0gBgMCINAAYj0gBgMCINAAYj0gBgMCINAAYj0gBgMCINAAYj0gBgMI/TG+gsyxMnV2KaQnUlqqpr1NgJk7Ri2fNatHixKspLJUlHSsuVl3eOFsyfq/z8J1RQUCC/P0H333+/8vLypHBIocYKyQ47fBrnfaN5lpRp0Jln6OmfL9ac2Q9p52efy++P/+s8ZSncVCU7+JWzh3EYs4ysWL/rURlpV0KKXHFJsu2wAsGgHpu/RHE+r0KN5Vow90mF25pUW1Wu26Y8rGn/NV7vvrleRUVFWrviWTW0uXT7XVO0bvlCWd4EuRPTFGqsdPpIjvpG86ws063/PV0zZs7SH97fpKKDxVq7/Gk1BNzH5vm05PbKk5SlYO1hp4/kGGYZWdz1KH3cYYeCCtYf/Rt0/qLlGnP15crMSD36TZdbCoe05MU1uumGMcru3V/7S2s0/IKhcllSWmaWXJZUWVUtO9AqyxPv4EnM8E3muXjFat005jql+YLau3ePRpx/rlwul1LirfZ5SpJt204dwwjMMrK469Ea6bYmSdL6Da8prWuKRgw7V5IlT3K2ZLlVWVGhbTsKdN3oHyjUVK3+PbO0ZXuBAmFLB4v2ac/+A2puaZXl80tWVI4gor7JPLfv+FT/eeWlkh1Wbu4Abd6+Q4FgUIeKDx+dZ2tAnqQshZuqnT2Mw5hlZHHXo/Rxx3Gvrt8gK9SmrTt2alfhPk2ber8WLZyndz8s0FWjLpfLDipkhzRi2BD9Ze8h3TZ5mgb06a0zB56h9J79ZLk9ssNBp49hjH81z++P+o7cbrck6aIRI/Snjz/UbZMf1IC+OTozt78yevVTqKladrDV4VOYgVlGVizf9aiO9OpVKxWqOyJ3UjeNG3+LZk2dpMz0VG3d9pFuH3e9LLdPslwqOnBQ6ZlZennpApVWVGv6I08oUU2yQ4lSgItw3L+c583Xtb9vf1GR0lO76uXn5qukskYPPb5QfqtVdqDNwd2bhVlGVizf9aiO9HHhllpZbp/ciZlyxSdp//596tm9m0JN1fKkdFevAWl6Ztkv9eor6+SLi9Os2bPlTukhhYNHP/HF3/iH8+yR3f79Ht27a/O2Hfrt628pzt9Fs2bOlLtL+rHFYYUayhzauXmYZWTF4l23OvnhhB2o3BfpvcQkb0aOJIl5RoY3I4dZRhDzjJxjd93q6LrofJIOADGCSAOAwYg0ABiMSAOAwYg0ABiMSAOAwYg0ABiMSAOAwYg0ABiMSAOAwYg0ABiMSAOAwYg0ABiMSAOAwYg0ABiMSAOAwYg0ABiMSAOAwYg0ABiMSAOAwYg0ABiMSAOAwSzbtjuzrlOLACDGWR1dwG/SAGAwT2cXBir3RXIfMcubkSOJeUaKNyOHWUYQ84yc43e9o/hNGgAMRqQBwGBEGgAMRqQBwGBEGgAMRqQBwGBEGgAMRqQBwGBEGgAMRqQBwGBEGgAMRqQBwGBEGgAMRqQBwGBEGgAMRqQBwGBEGgAMRqQBwGBEGgAMRqQBwGBEGgAMRqQBwGAepzfQWZYnTq7ENIXqSlRVU6sxt07WiueXaPFzz6uiolySdKS0XHl552jB/LnKz39CBQUF8vvjdf999yvvnDzJthVqKJfssMOncU4gGNTMJxbqSEmZ2gIB/WT8DRp0Vq7G3DpZw4bkac/+g/L74yVJR0rKNGhgrhqbm9XW1qbGphb5/fG6985b1aVLom6ceLf++PoaxcX5HD6VM5jliRHrdz0qI+1KSJErLkm2HVYgGNSjc3+u+AS/XN54PfXkowq3NqiuoVG3TXlY0/5rvN59c72Kioq0dsWzami1dfvke7Vu+UJZvkS5/KkKN1U5fSTHvPH799Q1OUk/nTVVtXX1uv6Wu9Q/5zTV1Tdo+yd/0u3jf6ix116luvoG3Tr5QaWldtUXhXvlcbu1/hfPqa6+QRPvnqHMjHT5vF6nj+MoZhl53PUofdxhh4IK1pdKkuYvWq6x116trPRUhdua29+z5MU1uumGMcru3V/7S2s0/IKhcllSWla2XC6psqpadqBZLm+CU8cwwpWXXazJE3/U/nVTU7OuvPwSnX5qT1128QXtry9esVp5Z+WqSxe/unfLVM5pp8rlcqlrSrJKyir0o7HXKj4+zokjGINZRh53PVoj3dYkSVq/4TWldU3RiPMHy/7aP2Oqamq1bUeBrhv9A4WaqtW/Z5a2bC9QIGzpUPFh7dlXpOaWVsm2JSsqRxAxfn+CEhP9ampq1rg77tPw84fomu9focREf/t7qmpq9cHWj1VZVaNJPx6njPQ07S06oEAwqJ8+vVQtLa06pXs3B09hBmYZedx1ybJtuzPr7EDlvkjvpWNcHo2f9ICsUJtkWdpVuE+n9e6tRQue1Dtvv636plbdedddCtWXSZJe+NVr2rzlQ+Xm5mr3ri/17JMzlZycJE/KKQrWFjt2DG9GjiTJyXmWlFVoyvQ5ampuVmZ6avs8E+LjddMP/kOJfr/efOd9BYJBxcX5dKSkTM0trcpIS1VpeYVkWep7em99vqtQZ58xQKuWzHPsLN6MHGYZQU7PU9LJdtetjq6LymfSx61etVKhuiOSpFsmTdMjMx9SZka6tn68Uz+ZcKMst0+yXCo6cFDpmVl6eekClVU3aPqsOUpO6iLL61c40OrwKZxVWV2j2+95SA/de6cuOG9w++u3TJqmvqf3VpfERH34UYEevPsODRzQV5KUv2CJ6hsa9bPZ01RSVqEZc+Zr5aKfadT14/XCwnynjuI4ZnnixPJdj+pI/zNFB4vVs3s3hZqq5Unprl4D0vTMsl/q1VfWyRfn06yZM+VO6fHXT3xj2LKX16m+oVFLX1qjpS+tkSQtfWrO37yn6GCxevbIbv+6S2Kidn72F9048W754nx6+N67vtU9m4pZfvti4a5H7+OOk4QJjztOJkb88/wkwjwjp7OPO6LzSToAxAgiDQAGI9IAYDAiDQAGI9IAYDAiDQAGI9IAYDAiDQAGI9IAYDAiDQAGI9IAYDAiDQAGI9IAYDAiDQAGI9IAYDAiDQAGI9IAYDAiDQAGI9IAYDAiDQAGI9IAYDAiDQAGs2zb7sy6Ti0CgBhndXSBp7M/qeWVxzq7FF+TMGaWJClQuc/hnZwcvBk5zDKCvBk53PUIOX7XO4rHHQBgMCINAAYj0gBgMCINAAYj0gBgMCINAAYj0gBgMCINAAYj0gBgMCINAAYj0gBgMCINAAYj0gBgMCINAAYj0gBgMCINAAYj0gBgMCINAAYj0gBgMCINAAYj0gBgMCINAAbzOL2BSKgOWLrx+be19NZRCkt6/I2dsiX175WtaRd0k9uyNO+jcu3cXaTEhARJ0oJrBinJbTu6b5NYnji5EtMUqitRVV2Txk64SyuWLdWiJc+poqxUkq0jpRXKy8vTgvlzlT/nMRV8+pn8/nhNnTZDg84+Q5JkB1oVbq5x9jAOY5YnTize9aiPdCAs5b9bqLi4OEnSok2FmnTFORqSKs3+Y7E2lYV1WbZbXxQd0eKxw5TqPf6HFb1/aJHmSkiRKy5Jth1WIBjUY/MXK87nUaixQk/lz5LcXtWUHtJtUx7StDt/pHd/t0FFh0u1dvnTqmts0R33zdS6ZQucPoYRmOWJE6t3Peofdzyzo0Kjz+ujrLRUSdK8K/toSKoUCNuqqmtQerxb4bCtA4dLlP/eHk145VP9z8E2h3dtFjsUVLC+VJI0f9Fyjbn6CmVmpB37riXZthYvf1k3XPtvysxI076iQ7po+HC5XC6lZWTJ7Xarus0rd3K25PY6dxADMMsTJ1bvelRH+vWDAaUmxuvCDKv9NbdlqaTVpeuXb1JNQ6NOTbTUYrt046iLNGdkHy26frDWffAnFTZa/+K/HFvstiZJ0voNrymta4pGDBssSbLcPrnik1Vx+IC27/hU13x/pFzxyRo4eJg+2LRJgWBQhw4dUuGevWosP6Bwc43cXTKdPIrjmOWJEct33f3II490Zt0jwb/8McJb6bi57/xZxZW1ev2Lcn25d792HmnQJQNOUbc4Wzece5rcyZn67Z+PaORpScpNj5ffLflcUnEwQXJ71C/Z7fQR5D3zUkly/tmj5dITCxapuLhYG363UbsK9+uTzz7XJecN1MY/bNKpvXpo6OBBsoNfqWdmskprGvXzpS+quLhYbrela6++UnFet9z+VIVb6xw7htufyiwjyO1PFXc9Mo7d9Uc7ui6qf5NeMTpPy0cP0rLrz1Zun9M155qhyt+4Wwdbjh4r0eeSy7J0sNmtW1dvVci2FQhLOwsPaEBqnMO7N8/qVSv10uJ5WrVsiXJzByh/xhRlpCZr68c7dfHwC+VO6iZJKjpYrLS0NP3ihWf144kT5fL4lJzURXL7ZIeDDp/CDMwysmL5rkf9B4f/14Th/TT79QJ5PW7F+3yaOSpXmb6wrhp2tsav+UQet1v/fv5A9UkMO71VY7kT0yXLkrtLhtwp3VVUXKKe2Rmyg1/JndJDPfun65llv9Srv35Fvrg4zZo1S+6U7pIthRornN6+UZjliRMrd92y7U598mm3vPJYpPcSkxLGzJIkBSr3ObyTk4M3I4dZRpA3I0fc9cg4dtc7/IA8qh93AMDJjkgDgMGINAAYjEgDgMGINAAYjEgDgMGINAAYjEgDgMGINAAYjEgDgMGINAAYjEgDgMGINAAYjEgDgMGINAAYjEgDgMGINAAYjEgDgMGINAAYjEgDgMGINAAYjEgDgMEs27Y7s65TiwAgxlkdXeD5tn4QAKDjeNwBAAYj0gBgMCINAAYj0gBgMCINAAYj0gBgMCINAAYj0gBgMCINAAYj0gBgMCINAAYj0gBgsP8FEdsMbeZm6awAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_data = levelling(training_data,1.2)\n",
    "heatmap(training_data)\n",
    "#guardar o novo dataset em dataset, var global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[99, 55, 121, 121, 55, 99, 121, 121, 121, 121, 106, 121, 121, 121, 121, 106]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "testing_data = levelling(testing_data,1.2)\n",
    "heatmap(testing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training the models & Classifying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Creating a proper list of vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este step is only done here in order to reduce the probability of messing up and disconecting each X vector from the correspondant Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eXifY(data):\n",
    "    X, Y = [element[0:-1] for element in data], [element[-1] for element in data]\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(eXifY(training_data)[0]) == len(eXifY(training_data)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Training & Classifying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the goal is the comparison of the quality of the classifications according to the type of context (number of \n",
    "coordinates given), we are going to train 4 models and test them to see the differences in success rate.\n",
    "Below are defined the training and testing functions, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def training(X,Y):\n",
    "   \n",
    "    nfolds=3 #3 means a 3-fold cross-validation\n",
    "    Cs = [1e5,1e6,10e4] #parameter 1\n",
    "    gammas = [1e-5,1e-4,1e-6] #parameter 2  \n",
    "    param_grid = {'C': Cs, 'gamma' : gammas} #all in one grid\n",
    "    grid_search2 = GridSearchCV(svm.SVC(kernel='rbf'), param_grid, cv=nfolds) #svm classifier\n",
    "    grid_search2.fit(X, Y) #fitting the data\n",
    "    best=grid_search2.best_params_ \n",
    "\n",
    "    clf = SVC(C= best['C'],gamma=best['gamma']) #creating the model with the best parameters\n",
    "    clf.fit(X, Y) #fitting the model to the data\n",
    "\n",
    "    now = datetime.datetime.now()\n",
    "    timestamp = str(now.strftime(\"%d-%m-%Y_%Hh%Mm%Ss\")) #the current day and time to have in the classifier name \n",
    "    \n",
    "    #to insert in the name of the classifier and text files which of the 4 groups of coordinates is the classifier using\n",
    "    if str(len(X[0])) == '10': #(head)\n",
    "        datatype='Head'\n",
    "    if str(len(X[0])) == '14': #(head + hands)\n",
    "        datatype='Head_Hands'\n",
    "    if str(len(X[0])) == '42': #(head + context data)\n",
    "        datatype='Head_Context_data'\n",
    "    if str(len(X[0])) == '46': #(all) \n",
    "        datatype='All'\n",
    "     \n",
    "    info_classif='classifier_' + timestamp + '_' + datatype +'_info.txt'\n",
    "    with open(info_classif, 'w+')  as info:\n",
    "        info.write('Group of Coordinates: '+ datatype + '\\n')\n",
    "        info.write('Type of classifier: SVM\\n') # python will convert \\n to os.linesep\n",
    "        info.write('C:'+str(best['C'])+'\\n')\n",
    "        info.write('Gamma:'+str(best['gamma'])+'\\n')\n",
    "\n",
    "    \n",
    "    classif = 'classifier_'+ timestamp + '_'+ datatype +'.joblib'\n",
    "    dump(clf, classif) \n",
    "                       \n",
    "    return classif,info_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def testing(X,Y,classif,info_classif):\n",
    "    \n",
    "    clf  = joblib.load(classif)\n",
    "    result = clf.score(X, Y)\n",
    "    \n",
    "    Qpredicted= []\n",
    "    i=0\n",
    "    length=len(X)\n",
    "\n",
    "    while i != length:\n",
    "        Qpredicted+= [str(clf.predict(np.array([X[i]]))).strip('['+']'+'\"')] #predict\n",
    "        Y[i]= str(Y[i]) #converting to a string\n",
    "        i+=1\n",
    "        \n",
    "    print('The percentage of success was: ' + str(result*100)+ ' %\\n')\n",
    "    with open(info_classif, 'a')  as info:\n",
    "        info.write('\\n----\\n')\n",
    "        info.write('The percentage of success was: ' + str(result*100)+ ' %\\n')\n",
    "        \n",
    "    CONF= confusion_matrix(np.array(Y), np.array(Qpredicted))\n",
    "\n",
    "    return CONF, result, Qpredicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 Using only the face keypoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're only using  the keypoints of the head, we'll delete context information about the difference short/long distance object and hands coordinates. <br> \n",
    "The head coordinates are the first 10 (5*2) (x,y)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we will:<br> \n",
    " - Delete the coordinates we don't need (mentioned before) from the whole training data;<br> \n",
    " - Train the model with only the head coordinates using the training function (defined before);<br> \n",
    " - Delete the coordinates we don't need (mentioned before) from the whole testing data;<br> \n",
    " - Test the model with only the head coordinates using the training function (defined before)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = eXifY(training_data)\n",
    "X = [element[:10] for element in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classif,info_classif=training(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = eXifY(testing_data)\n",
    "X = [element[:10] for element in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONF1, result, Qpredicted = testing(X,Y,classif,info_classif)\n",
    "#print(Qpredicted)\n",
    "#print(Y)\n",
    "print(CONF1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 Using only keypoints (face + hands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're only using  the keypoints of the head and the hands, we'll delete context information about the difference short/long distance object.<br> \n",
    "The keypoints (head + hands) coordinates are the first 10 (5*2) + 4 (2*2)(x,y), giving a total of 14.<br> \n",
    "The rest of the procedure is the same as in 3.2.1.:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we will:<br> \n",
    " - Delete the coordinates we don't need (mentioned before) from the whole training data;<br> \n",
    " - Train the model with only the head + hand coordinates using the training function (defined before);<br> \n",
    " - Delete the coordinates we don't need (mentioned before) from the whole testing data;<br> \n",
    " - Test the model with only the head + hand coordinates using the training function (defined before)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X, Y = eXifY(training_data)\n",
    "X = [element[:14] for element in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classif,info_classif=training(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = eXifY(testing_data)\n",
    "X = [element[:14] for element in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONF2, result, Qpredicted = testing(X,Y,classif,info_classif)\n",
    "#print(Qpredicted)\n",
    "#print(Y)\n",
    "print(CONF2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.3 Using only the keypoints of the head and context data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're only using  the keypoints of the head and the context information about the difference short/long distance object, we'll delete the hand coordinates.<br> \n",
    "The keypoints of the head coordinates are the first 10 (5*2) and the context data goes from the 15 to the 46 coordinates (but on the code we have to do it from 14th to start on the 15th) giving a total of 42 coordinates.<br>\n",
    "The rest of the procedure is the same as in 3.2.1.:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we will:<br>\n",
    " - Delete the coordinates we don't need (mentioned before) from the whole training data;<br>\n",
    " - Train the model with only the head + context data coordinates using the training function (defined before);<br>\n",
    " - Delete the coordinates we don't need (mentioned before) from the whole testing data;<br>\n",
    " - Test the model with only the head + context data coordinates using the training function (defined before)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X, Y = eXifY(training_data)\n",
    "X = [element[:10] + element[14:] for element in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classif,info_classif=training(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = eXifY(testing_data)\n",
    "X = [element[:10] + element[14:] for element in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONF3, result, Qpredicted = testing(X,Y,classif,info_classif)\n",
    "#print(Qpredicted)\n",
    "#print(Y)\n",
    "print(CONF3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.4 Using all the coordinates (keypoints of the head, hands and context data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are using the whole set of coordinates (keypoints of the head, hands and context data) giving a total of 46 coordinates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we will:<br>\n",
    " - Create the training data divided into X (coordinates) and Y (quadrants) like before;<br>\n",
    " - Train the model with all the 46 coordinates using the training function (defined before);<br>\n",
    " - Create the test data divided into X (coordinates) and Y (quadrants) like before; <br>\n",
    " - Test the model with all the coordinates using the training function (defined before)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X, Y = eXifY(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classif,info_classif=training(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = eXifY(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONF4, result, Qpredicted = testing(X,Y,classif,info_classif)\n",
    "#print(Qpredicted)\n",
    "#print(Y)\n",
    "print(CONF4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Comparing classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, at last, we compare the Confusion Matrices of the 4 groups of coordinates. And with a nice layout!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()  \n",
    "plt.rcParams[\"figure.figsize\"] = (4,4)\n",
    "df = DataFrame(CONF1) #, index=Index, columns=Cols - if defined before\n",
    "sns.heatmap(df, annot=True, cmap=\"YlGnBu\",cbar=False) #cbar=True is an option but it appears float values\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title('Confusion Matrix Head')\n",
    "plt.show()\n",
    "\n",
    "plt.figure() \n",
    "plt.rcParams[\"figure.figsize\"] = (4,4)\n",
    "df = DataFrame(CONF2) #, index=Index, columns=Cols - if defined before\n",
    "sns.heatmap(df, annot=True, cmap=\"YlGnBu\",cbar=False) #cbar=True is an option but it appears float values\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title('Confusion Matrix Head + Hands')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.rcParams[\"figure.figsize\"] = (4,4)\n",
    "df = DataFrame(CONF3) #, index=Index, columns=Cols - if defined before\n",
    "sns.heatmap(df, annot=True, cmap=\"YlGnBu\",cbar=False) #cbar=True is an option but it appears float values\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title('Confusion Matrix Head + Context Data')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.rcParams[\"figure.figsize\"] = (4,4)\n",
    "df = DataFrame(CONF4) #, index=Index, columns=Cols - if defined before\n",
    "sns.heatmap(df, annot=True, cmap=\"YlGnBu\",cbar=False) #cbar=True is an option but it appears float values\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title('Confusion Matrix All')\n",
    "#plt.subplots_adjust(wspace=0.8, hspace=0.8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
